{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "sY_DWk_s9vxh",
        "colab_type": "code",
        "outputId": "0149f57d-057e-4a31-d89c-67399ae343c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorlayer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorlayer in /usr/local/lib/python3.6/dist-packages (1.11.1)\n",
            "Requirement already satisfied: scikit-learn<0.21,>=0.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (0.20.2)\n",
            "Requirement already satisfied: requests<2.21,>=2.19 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (2.20.1)\n",
            "Requirement already satisfied: matplotlib<3.1,>=2.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (3.0.2)\n",
            "Requirement already satisfied: tqdm<4.29,>=4.23 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (4.28.1)\n",
            "Requirement already satisfied: scipy<1.2,>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (1.1.0)\n",
            "Requirement already satisfied: lxml<4.3,>=4.2 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (4.2.6)\n",
            "Requirement already satisfied: scikit-image<0.15,>=0.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (0.14.1)\n",
            "Requirement already satisfied: wrapt<1.11,>=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (1.10.11)\n",
            "Requirement already satisfied: imageio<2.5,>=2.3 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (2.4.1)\n",
            "Requirement already satisfied: progressbar2<3.39,>=3.38 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (3.38.0)\n",
            "Requirement already satisfied: numpy<1.16,>=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorlayer) (1.14.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer) (2018.11.29)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer) (1.22)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<2.21,>=2.19->tensorlayer) (3.0.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer) (2.3.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib<3.1,>=2.2->tensorlayer) (2.5.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (1.11.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (2.2)\n",
            "Requirement already satisfied: dask[array]>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (0.20.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (5.4.1)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image<0.15,>=0.14->tensorlayer) (0.6.1)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2<3.39,>=3.38->tensorlayer) (2.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib<3.1,>=2.2->tensorlayer) (40.6.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image<0.15,>=0.14->tensorlayer) (4.3.0)\n",
            "Requirement already satisfied: toolz>=0.7.3; extra == \"array\" in /usr/local/lib/python3.6/dist-packages (from dask[array]>=0.9.0->scikit-image<0.15,>=0.14->tensorlayer) (0.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dz5cCQ7h23WO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Connecting to Gdrive"
      ]
    },
    {
      "metadata": {
        "id": "z7kg-yn_2w0H",
        "colab_type": "code",
        "outputId": "cbca7db3-f075-45fc-81c7-1f89f420c0cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "gdrive = GoogleDrive(gauth)\n",
        "\n",
        "# PyDrive reference:\n",
        "# https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html\n",
        "\n",
        "# 2. Create & upload a file text file.\n",
        "uploaded = gdrive.CreateFile({'title': 'Sample upload.txt'})\n",
        "uploaded.SetContentString('Sample upload file content')\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "\n",
        "# 3. Load a file by ID and print its contents.\n",
        "downloaded = gdrive.CreateFile({'id': uploaded.get('id')})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1jm_CZnJshY8B_lSjlfuT8l_OzMfKIudr\n",
            "Downloaded content \"Sample upload file content\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D1XNyN8c28ot",
        "colab_type": "code",
        "outputId": "899650a2-aa21-4ec3-cad1-86ae18125ba1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4_CLNI6V_i0c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "XTGscVQ-_ldC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorlayer as tl\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from tensorlayer.layers import DenseLayer, EmbeddingInputlayer, Seq2Seq, retrieve_seq_length_op2\n",
        "\n",
        "sess_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VrLaPNG4Ks3Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "drive_path = 'gdrive/My Drive/masters/kpis/chatbot/data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5ypN2IOCTQu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "metadata": {
        "id": "Pf6E3_YcDTco",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(PATH=drive_path):\n",
        "    # read data control dictionaries\n",
        "    try:\n",
        "        with open(PATH + 'metadata.pkl', 'rb') as f:\n",
        "            metadata = pickle.load(f)\n",
        "    except:\n",
        "        metadata = None\n",
        "    # read numpy arrays\n",
        "    idx_q = np.load(PATH + 'idx_q.npy')\n",
        "    idx_a = np.load(PATH + 'idx_a.npy')\n",
        "    return metadata, idx_q, idx_a\n",
        "  \n",
        "'''\n",
        " split data into train (70%), test (15%) and valid(15%)\n",
        "    return tuple( (trainX, trainY), (testX,testY), (validX,validY) )\n",
        "\n",
        "'''\n",
        "def split_dataset(x, y, ratio = [0.7, 0.15, 0.15] ):\n",
        "    # number of examples\n",
        "    data_len = len(x)\n",
        "    lens = [ int(data_len*item) for item in ratio ]\n",
        "\n",
        "    trainX, trainY = x[:lens[0]], y[:lens[0]]\n",
        "    testX, testY = x[lens[0]:lens[0]+lens[1]], y[lens[0]:lens[0]+lens[1]]\n",
        "    validX, validY = x[-lens[-1]:], y[-lens[-1]:]\n",
        "\n",
        "    return (trainX,trainY), (testX,testY), (validX,validY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xf-LNzv3BLs9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def initial_setup():\n",
        "    metadata, idx_q, idx_a = load_data()\n",
        "    (trainX, trainY), (testX, testY), (validX, validY) = split_dataset(idx_q, idx_a)\n",
        "    trainX = tl.prepro.remove_pad_sequences(trainX.tolist())\n",
        "    trainY = tl.prepro.remove_pad_sequences(trainY.tolist())\n",
        "    testX = tl.prepro.remove_pad_sequences(testX.tolist())\n",
        "    testY = tl.prepro.remove_pad_sequences(testY.tolist())\n",
        "    validX = tl.prepro.remove_pad_sequences(validX.tolist())\n",
        "    validY = tl.prepro.remove_pad_sequences(validY.tolist())\n",
        "    return metadata, trainX, trainY, testX, testY, validX, validY"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJbCx3dKCgJW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Mr_G96PCgv5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating the LSTM model "
      ]
    },
    {
      "metadata": {
        "id": "8SSBz9FRCAxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Creates the LSTM Model\n",
        "\"\"\"\n",
        "def create_model(encode_seqs, decode_seqs, src_vocab_size, emb_dim, is_train=True, reuse=False):\n",
        "    with tf.variable_scope(\"model\", reuse=reuse):\n",
        "        # for chatbot, you can use the same embedding layer,\n",
        "        # for translation, you may want to use 2 seperated embedding layers\n",
        "        with tf.variable_scope(\"embedding\") as vs:\n",
        "            net_encode = EmbeddingInputlayer(\n",
        "                inputs = encode_seqs,\n",
        "                vocabulary_size = src_vocab_size,\n",
        "                embedding_size = emb_dim,\n",
        "                name = 'seq_embedding')\n",
        "            vs.reuse_variables()\n",
        "            net_decode = EmbeddingInputlayer(\n",
        "                inputs = decode_seqs,\n",
        "                vocabulary_size = src_vocab_size,\n",
        "                embedding_size = emb_dim,\n",
        "                name = 'seq_embedding')\n",
        "            \n",
        "        net_rnn = Seq2Seq(net_encode, net_decode,\n",
        "                cell_fn = tf.nn.rnn_cell.LSTMCell,\n",
        "                n_hidden = emb_dim,\n",
        "                initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
        "                encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
        "                decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
        "                initial_state_encode = None,\n",
        "                dropout = (0.5 if is_train else None),\n",
        "                n_layer = 3,\n",
        "                return_seq_2d = True,\n",
        "                name = 'seq2seq')\n",
        "\n",
        "        net_out = DenseLayer(net_rnn, n_units=src_vocab_size, act=tf.identity, name='output')\n",
        "    return net_out, net_rnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-0iMk0tdwdTQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**CREATING A FILE IN GOOGLE DRIVE TO SAVE MODEL**"
      ]
    },
    {
      "metadata": {
        "id": "fBGc8M7x4Cio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def does_file_exists_in_gdrive(name='', folder_id = \"root\", is_folder= True):\n",
        "  file_list = gdrive.ListFile({'q':\"'{0}' in parents and trashed=false\".format(folder_id), 'maxResults': 10}).GetList()\n",
        "  file_exists = False\n",
        "  id =None\n",
        "\n",
        "  for file1 in file_list:\n",
        "    if(file1['title'] == name):\n",
        "      file_exists = True\n",
        "      id = file1['id']\n",
        "      break\n",
        "  if not file_exists and is_folder:\n",
        "    folder_metadata = {'title' : name, 'mimeType' : 'application/vnd.google-apps.folder'}\n",
        "    folder = gdrive.CreateFile(folder_metadata)\n",
        "    folder.Upload()\n",
        "    id = folder['id']\n",
        "  return (id, file_exists)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tle9fBwLwlXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "id,_ = does_file_exists_in_gdrive(name='Chatbot_model', folder_id=\"root\", is_folder=True)\n",
        "file_id, doesFileExist = does_file_exists_in_gdrive(name='model.npz', folder_id=id, is_folder= False)\n",
        "\n",
        "if doesFileExist:\n",
        "  model_file = gdrive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": id}], \"id\": file_id})\n",
        "else:\n",
        "  model_file = gdrive.CreateFile({\"parents\": [{\"kind\": \"drive#fileLink\", \"id\": id}]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zu5v4BUJwcdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8696d753-0bd7-41d8-dd1a-009cc392a45c"
      },
      "cell_type": "code",
      "source": [
        "_"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "Q1HtLmOmCcod",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training utility "
      ]
    },
    {
      "metadata": {
        "id": "mV5IOKkPClj-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(batch_size, num_epochs, learning_rate, inference_mode):\n",
        "\n",
        "    metadata, trainX, trainY, testX, testY, validX, validY = initial_setup()\n",
        "\n",
        "    # Parameters\n",
        "    src_len = len(trainX)\n",
        "    tgt_len = len(trainY)\n",
        "\n",
        "    assert src_len == tgt_len\n",
        "    print(src_len)\n",
        "    \n",
        "    n_step = src_len // batch_size\n",
        "    src_vocab_size = len(metadata['idx2w']) # 8002 (0~8001)\n",
        "    emb_dim = 1024\n",
        "\n",
        "    word2idx = metadata['w2idx']   # dict  word 2 index\n",
        "    idx2word = metadata['idx2w']   # list index 2 word\n",
        "\n",
        "    unk_id = word2idx['unk']   # 1\n",
        "    pad_id = word2idx['_']     # 0\n",
        "\n",
        "    start_id = src_vocab_size  # 8002\n",
        "    end_id = src_vocab_size + 1  # 8003\n",
        "\n",
        "    word2idx.update({'start_id': start_id})\n",
        "    word2idx.update({'end_id': end_id})\n",
        "    idx2word = idx2word + ['start_id', 'end_id']\n",
        "\n",
        "    src_vocab_size = tgt_vocab_size = src_vocab_size + 2\n",
        "\n",
        "    \"\"\" A data for Seq2Seq should look like this:\n",
        "    input_seqs : ['how', 'are', 'you', '<PAD_ID'>]\n",
        "    decode_seqs : ['<START_ID>', 'I', 'am', 'fine', '<PAD_ID'>]\n",
        "    target_seqs : ['I', 'am', 'fine', '<END_ID>', '<PAD_ID'>]\n",
        "    target_mask : [1, 1, 1, 1, 0]\n",
        "    \"\"\"\n",
        "    # Preprocessing\n",
        "    target_seqs = tl.prepro.sequences_add_end_id([trainY[10]], end_id=end_id)[0]\n",
        "    decode_seqs = tl.prepro.sequences_add_start_id([trainY[10]], start_id=start_id, remove_last=False)[0]\n",
        "    target_mask = tl.prepro.sequences_get_mask([target_seqs])[0]\n",
        "    if not inference_mode:\n",
        "        print(\"encode_seqs\", [idx2word[id] for id in trainX[10]])\n",
        "        print(\"target_seqs\", [idx2word[id] for id in target_seqs])\n",
        "        print(\"decode_seqs\", [idx2word[id] for id in decode_seqs])\n",
        "        print(\"target_mask\", target_mask)\n",
        "        print(len(target_seqs), len(decode_seqs), len(target_mask))\n",
        "\n",
        "    # Init Session\n",
        "    tf.reset_default_graph()\n",
        "    sess = tf.Session(config=sess_config)\n",
        "\n",
        "    # Training Data Placeholders\n",
        "    encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\n",
        "    decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\n",
        "    target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\n",
        "    target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\") \n",
        "\n",
        "    net_out, _ = create_model(encode_seqs, decode_seqs, src_vocab_size, emb_dim, is_train=True, reuse=False)\n",
        "    net_out.print_params(False)\n",
        "\n",
        "    # Inference Data Placeholders\n",
        "    encode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"encode_seqs\")\n",
        "    decode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"decode_seqs\")\n",
        "\n",
        "    net, net_rnn = create_model(encode_seqs2, decode_seqs2, src_vocab_size, emb_dim, is_train=False, reuse=True)\n",
        "    y = tf.nn.softmax(net.outputs)\n",
        "\n",
        "    # Loss Function\n",
        "    loss = tl.cost.cross_entropy_seq_with_mask(logits=net_out.outputs, target_seqs=target_seqs, \n",
        "                                                input_mask=target_mask, return_details=False, name='cost')\n",
        "\n",
        "    # Optimizer\n",
        "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
        "\n",
        "    # Init Vars\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Load Model\n",
        "    tl.files.load_and_assign_npz(sess=sess, name='gdrive/My Drive/Chatbot_model/model.npz', network=net_out)\n",
        "    tl.files.load_and_assign_npz(sess=sess, name='model.npz', network=net)\n",
        "\n",
        "    \"\"\"\n",
        "    Inference using pre-trained model\n",
        "    \"\"\"\n",
        "    def inference(seed):\n",
        "        seed_id = [word2idx.get(w, unk_id) for w in seed.split(\" \")]\n",
        "        \n",
        "        # Encode and get state\n",
        "        state = sess.run(net_rnn.final_state_encode,\n",
        "                        {encode_seqs2: [seed_id]})\n",
        "        # Decode, feed start_id and get first word [https://github.com/zsdonghao/tensorlayer/blob/master/example/tutorial_ptb_lstm_state_is_tuple.py]\n",
        "        o, state = sess.run([y, net_rnn.final_state_decode],\n",
        "                        {net_rnn.initial_state_decode: state,\n",
        "                        decode_seqs2: [[start_id]]})\n",
        "        w_id = tl.nlp.sample_top(o[0], top_k=3)\n",
        "        w = idx2word[w_id]\n",
        "        # Decode and feed state iteratively\n",
        "        sentence = [w]\n",
        "        for _ in range(30): # max sentence length\n",
        "            o, state = sess.run([y, net_rnn.final_state_decode],\n",
        "                            {net_rnn.initial_state_decode: state,\n",
        "                            decode_seqs2: [[w_id]]})\n",
        "            w_id = tl.nlp.sample_top(o[0], top_k=2)\n",
        "            w = idx2word[w_id]\n",
        "            if w_id == end_id:\n",
        "                break\n",
        "            sentence = sentence + [w]\n",
        "        return sentence\n",
        "\n",
        "    if inference_mode:\n",
        "        print('Inference Mode')\n",
        "        print('--------------')\n",
        "        while True:\n",
        "            input_seq = input('Enter Query: ')\n",
        "            sentence = inference(input_seq)\n",
        "            print(\" >\", ' '.join(sentence))\n",
        "    else:\n",
        "        seeds = [\"you want to turn twitter followers into blog readers\",\n",
        "                 \"does the dog also have polio\", \n",
        "                 \"wow, this is such a gorgeous photo. what did you use to take it\",\n",
        "                 \"i bet these guys that are playing d for philly feel so fresh\"]\n",
        "        for epoch in range(num_epochs):\n",
        "            trainX, trainY = shuffle(trainX, trainY, random_state=0)\n",
        "            total_loss, n_iter = 0, 0\n",
        "            for X, Y in tqdm(tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=batch_size, shuffle=False), \n",
        "                            total=n_step, desc='Epoch[{}/{}]'.format(epoch + 1, num_epochs), leave=False):\n",
        "\n",
        "                X = tl.prepro.pad_sequences(X)\n",
        "                _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)\n",
        "                _target_seqs = tl.prepro.pad_sequences(_target_seqs)\n",
        "                _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)\n",
        "                _decode_seqs = tl.prepro.pad_sequences(_decode_seqs)\n",
        "                _target_mask = tl.prepro.sequences_get_mask(_target_seqs)\n",
        "                ## Uncomment to view the data here\n",
        "                # for i in range(len(X)):\n",
        "                #     print(i, [idx2word[id] for id in X[i]])\n",
        "                #     print(i, [idx2word[id] for id in Y[i]])\n",
        "                #     print(i, [idx2word[id] for id in _target_seqs[i]])\n",
        "                #     print(i, [idx2word[id] for id in _decode_seqs[i]])\n",
        "                #     print(i, _target_mask[i])\n",
        "                #     print(len(_target_seqs[i]), len(_decode_seqs[i]), len(_target_mask[i]))\n",
        "                _, loss_iter = sess.run([train_op, loss], {encode_seqs: X, decode_seqs: _decode_seqs,\n",
        "                                target_seqs: _target_seqs, target_mask: _target_mask})\n",
        "                total_loss += loss_iter\n",
        "                n_iter += 1\n",
        "            print('n_iter is {0}'.format(n_iter))\n",
        "            # printing average loss after every epoch\n",
        "            print('Epoch [{}/{}]: loss {:.4f}'.format(epoch + 1, num_epochs, total_loss / n_iter))\n",
        "            \n",
        "            # inference after every epoch\n",
        "            for seed in seeds:\n",
        "                print(\"Query >\", seed)\n",
        "                for _ in range(5):\n",
        "                    sentence = inference(seed)\n",
        "                    print(\" >\", ' '.join(sentence))\n",
        "            \n",
        "            # saving the model\n",
        "            tl.files.save_npz(net.all_params, name='model.npz', sess=sess)\n",
        "            model_file.SetContentFile('model.npz')\n",
        "            model_file.Upload()\n",
        "    # session cleanup\n",
        "    sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3Y3lNMxCsW0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training"
      ]
    },
    {
      "metadata": {
        "id": "iLirva1VJOhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "c8d0d9cb-4480-49d6-d07a-7a50fcdcb795"
      },
      "cell_type": "code",
      "source": [
        "train(batch_size=32, num_epochs = 50, learning_rate = 0.004, inference_mode= False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "91295\n",
            "encode_seqs ['wednesday', 'and', 'thursday', 'in', 'seattle', 's', 'big', 'conference', '']\n",
            "target_seqs ['wish', 'but', 'cant', 'travel', 'enjoy', 'end_id']\n",
            "decode_seqs ['start_id', 'wish', 'but', 'cant', 'travel', 'enjoy']\n",
            "target_mask [1 1 1 1 1 1]\n",
            "6 6 6\n",
            "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
            "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
            "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 1024 cell_fn: LSTMCell dropout: 0.5 n_layer: 3\n",
            "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 1024, in_dim: 3 in_shape: (32, ?, 1024) cell_fn: LSTMCell dropout: 0.5 n_layer: 3\n",
            "[TL]        batch_size (concurrent processes): 32\n",
            "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 1024, in_dim: 3 in_shape: (32, ?, 1024) cell_fn: LSTMCell dropout: 0.5 n_layer: 3\n",
            "[TL]        batch_size (concurrent processes): 32\n",
            "[TL] DenseLayer  model/output: 8004 No Activation\n",
            "[TL]   param   0: model/embedding/seq_embedding/embeddings:0 (8004, 1024)       float32_ref\n",
            "[TL]   param   1: model/seq2seq/encode/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
            "[TL]   param   2: model/seq2seq/encode/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0 (4096,)            float32_ref\n",
            "[TL]   param   3: model/seq2seq/encode/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
            "[TL]   param   4: model/seq2seq/encode/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0 (4096,)            float32_ref\n",
            "[TL]   param   5: model/seq2seq/encode/rnn/multi_rnn_cell/cell_2/lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
            "[TL]   param   6: model/seq2seq/encode/rnn/multi_rnn_cell/cell_2/lstm_cell/bias:0 (4096,)            float32_ref\n",
            "[TL]   param   7: model/seq2seq/decode/rnn/multi_rnn_cell/cell_0/lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
            "[TL]   param   8: model/seq2seq/decode/rnn/multi_rnn_cell/cell_0/lstm_cell/bias:0 (4096,)            float32_ref\n",
            "[TL]   param   9: model/seq2seq/decode/rnn/multi_rnn_cell/cell_1/lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
            "[TL]   param  10: model/seq2seq/decode/rnn/multi_rnn_cell/cell_1/lstm_cell/bias:0 (4096,)            float32_ref\n",
            "[TL]   param  11: model/seq2seq/decode/rnn/multi_rnn_cell/cell_2/lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
            "[TL]   param  12: model/seq2seq/decode/rnn/multi_rnn_cell/cell_2/lstm_cell/bias:0 (4096,)            float32_ref\n",
            "[TL]   param  13: model/output/W:0     (1024, 8004)       float32_ref\n",
            "[TL]   param  14: model/output/b:0     (8004,)            float32_ref\n",
            "[TL]   num of params: 66756420\n",
            "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
            "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
            "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 1024 cell_fn: LSTMCell dropout: None n_layer: 3\n",
            "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 1024, in_dim: 3 in_shape: (1, ?, 1024) cell_fn: LSTMCell dropout: None n_layer: 3\n",
            "[TL]        batch_size (concurrent processes): 1\n",
            "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 1024, in_dim: 3 in_shape: (1, ?, 1024) cell_fn: LSTMCell dropout: None n_layer: 3\n",
            "[TL]        batch_size (concurrent processes): 1\n",
            "[TL] DenseLayer  model/output: 8004 No Activation\n",
            "[TL] [*] Load gdrive/My Drive/Chatbot_model/model.npz SUCCESS!\n",
            "[TL] [*] Load model.npz SUCCESS!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch[1/50]:  10%|▉         | 271/2852 [01:48<16:58,  2.54it/s]"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}